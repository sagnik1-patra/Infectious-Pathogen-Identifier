{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53fabbfa-b4d2-4a41-b62a-5d4ab5cec9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset from Excel...\n",
      "[INFO] Loaded dataset shape: (598, 6)\n",
      "[INFO] Columns: ['ATTAAAGGTT', 'TATACCTTCC', 'CAGGTAACAA', 'ACCAACCAAC', 'TTTCGATCTC', 50]\n",
      "[SAVED] C:\\Users\\NXTWAVE\\Downloads\\Infectious Pathogen Identifier\\dataset.json\n",
      "[SAVED] C:\\Users\\NXTWAVE\\Downloads\\Infectious Pathogen Identifier\\dataset.yaml\n",
      "[SAVED] C:\\Users\\NXTWAVE\\Downloads\\Infectious Pathogen Identifier\\dataset.pkl\n",
      "[SAVED] C:\\Users\\NXTWAVE\\Downloads\\Infectious Pathogen Identifier\\dataset.h5\n",
      "\n",
      "✅ [DONE] Phase 1 complete.\n",
      "All 4 artifacts saved under:\n",
      "C:\\Users\\NXTWAVE\\Downloads\\Infectious Pathogen Identifier\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# PATH SETTINGS\n",
    "# ----------------------------------------------------\n",
    "INPUT_EXCEL = r\"C:\\Users\\NXTWAVE\\Downloads\\Infectious Pathogen Identifier\\archive\\Virus_Genome.xlsx\"\n",
    "OUTPUT_DIR  = r\"C:\\Users\\NXTWAVE\\Downloads\\Infectious Pathogen Identifier\"\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. Load dataset\n",
    "# ----------------------------------------------------\n",
    "print(\"[INFO] Loading dataset from Excel...\")\n",
    "df = pd.read_excel(INPUT_EXCEL)\n",
    "print(f\"[INFO] Loaded dataset shape: {df.shape}\")\n",
    "print(f\"[INFO] Columns: {list(df.columns)}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. Basic cleaning (safe for numeric headers)\n",
    "# ----------------------------------------------------\n",
    "df = df.dropna(how=\"all\")          # drop fully empty rows\n",
    "df = df.fillna(\"NA\")               # fill partial NaNs\n",
    "\n",
    "# Ensure all column names are strings\n",
    "df.columns = [str(c).strip().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "# Add index ID if not exists\n",
    "if \"Sample_ID\" not in df.columns:\n",
    "    df.insert(0, \"Sample_ID\", [f\"S{i+1:05d}\" for i in range(len(df))])\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. Convert to dictionary for export\n",
    "# ----------------------------------------------------\n",
    "dataset_dict = {\n",
    "    \"meta\": {\n",
    "        \"project\": \"PathoNet — Infectious Pathogen Identifier\",\n",
    "        \"source_file\": INPUT_EXCEL,\n",
    "        \"n_rows\": len(df),\n",
    "        \"n_cols\": len(df.columns),\n",
    "        \"created_on\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"notes\": \"Virus genome dataset converted to multiple formats (.h5, .pkl, .yaml, .json)\"\n",
    "    },\n",
    "    \"data\": df.to_dict(orient=\"list\")\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. Define save functions\n",
    "# ----------------------------------------------------\n",
    "def save_json(obj, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "    print(f\"[SAVED] {path}\")\n",
    "\n",
    "def save_yaml(obj, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        yaml.dump(obj, f, sort_keys=False)\n",
    "    print(f\"[SAVED] {path}\")\n",
    "\n",
    "def save_pickle(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "    print(f\"[SAVED] {path}\")\n",
    "\n",
    "def save_h5(df, meta, path):\n",
    "    with h5py.File(path, \"w\") as hf:\n",
    "        # create datasets for each column\n",
    "        grp = hf.create_group(\"data\")\n",
    "        for col in df.columns:\n",
    "            data = df[col].astype(str).values\n",
    "            dt = h5py.string_dtype(encoding='utf-8')\n",
    "            grp.create_dataset(col, data=data, dtype=dt)\n",
    "        # metadata\n",
    "        meta_grp = hf.create_group(\"meta\")\n",
    "        for k, v in meta.items():\n",
    "            meta_grp.attrs[k] = str(v)\n",
    "    print(f\"[SAVED] {path}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. Save all formats\n",
    "# ----------------------------------------------------\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "json_path = os.path.join(OUTPUT_DIR, \"dataset.json\")\n",
    "yaml_path = os.path.join(OUTPUT_DIR, \"dataset.yaml\")\n",
    "pkl_path  = os.path.join(OUTPUT_DIR, \"dataset.pkl\")\n",
    "h5_path   = os.path.join(OUTPUT_DIR, \"dataset.h5\")\n",
    "\n",
    "save_json(dataset_dict, json_path)\n",
    "save_yaml(dataset_dict, yaml_path)\n",
    "save_pickle(dataset_dict, pkl_path)\n",
    "save_h5(df, dataset_dict[\"meta\"], h5_path)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 6. Summary\n",
    "# ----------------------------------------------------\n",
    "print(\"\\n✅ [DONE] Phase 1 complete.\")\n",
    "print(f\"All 4 artifacts saved under:\\n{OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b2697-a482-4f5f-ac20-34a6cb4e7618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
